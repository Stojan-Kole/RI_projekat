{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T20:51:45.081152Z",
     "start_time": "2025-01-30T20:51:23.179779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer\n",
    "from torch.utils.data import Dataset\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from datasets import load_dataset\n",
    "import random\n",
    "from copy import deepcopy\n",
    "import optuna\n",
    "from torch.utils.data import DataLoader\n",
    "import wandb"
   ],
   "id": "1d223714e7b9977c",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T20:51:49.749417Z",
     "start_time": "2025-01-30T20:51:45.094563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize W&B\n",
    "wandb.init(\n",
    "    project=\"few-shot-multiset\",\n",
    "    name=\"maml-multiset-optuna\",\n",
    ")"
   ],
   "id": "da5df5b9973dfc16",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: kostic-stojan23 (kostic-stojan23-university-of-belgrade). Use `wandb login --relogin` to force relogin\n",
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Korisnik\\Desktop\\RI_projekat\\wandb\\run-20250130_215147-576zl4im</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kostic-stojan23-university-of-belgrade/few-shot-multiset/runs/576zl4im' target=\"_blank\">maml-multiset-optuna</a></strong> to <a href='https://wandb.ai/kostic-stojan23-university-of-belgrade/few-shot-multiset' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/kostic-stojan23-university-of-belgrade/few-shot-multiset' target=\"_blank\">https://wandb.ai/kostic-stojan23-university-of-belgrade/few-shot-multiset</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/kostic-stojan23-university-of-belgrade/few-shot-multiset/runs/576zl4im' target=\"_blank\">https://wandb.ai/kostic-stojan23-university-of-belgrade/few-shot-multiset/runs/576zl4im</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/kostic-stojan23-university-of-belgrade/few-shot-multiset/runs/576zl4im?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1f7feeffc50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T20:51:50.339141Z",
     "start_time": "2025-01-30T20:51:50.327546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_and_normalize(dataset_name):\n",
    "    dataset = load_dataset(dataset_name)\n",
    "\n",
    "    if dataset_name == \"amazon_polarity\":\n",
    "        def process(example):\n",
    "            return {\"text\": example[\"content\"], \"label\": example[\"label\"]}\n",
    "    elif dataset_name == \"yelp_polarity\":\n",
    "        def process(example):\n",
    "            return {\"text\": example[\"text\"], \"label\": example[\"label\"]}\n",
    "    elif dataset_name == \"sentiment140\":\n",
    "        def process(example):\n",
    "            label = 0 if example[\"sentiment\"] == 0 else 1  # Convert (0,4) to (0,1)\n",
    "            return {\"text\": example[\"text\"], \"label\": label}\n",
    "\n",
    "    dataset[\"train\"] = dataset[\"train\"].map(process)\n",
    "    dataset[\"test\"] = dataset[\"test\"].map(process)\n",
    "\n",
    "    return dataset[\"train\"], dataset[\"test\"]"
   ],
   "id": "7ef60eb3bcbaf04e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T20:52:09.359994Z",
     "start_time": "2025-01-30T20:51:50.360661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_names = [\"amazon_polarity\", \"yelp_polarity\", \"sentiment140\"]\n",
    "train_data, test_data = {}, {}\n",
    "\n",
    "for name in dataset_names:\n",
    "    train_data[name], test_data[name] = load_and_normalize(name)"
   ],
   "id": "252b4ccaf47d5f6f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T20:52:09.398571Z",
     "start_time": "2025-01-30T20:52:09.387393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class FewShotDataset(Dataset):\n",
    "    def __init__(self, data, num_support, num_query):\n",
    "        self.data = data\n",
    "        self.num_support = num_support\n",
    "        self.num_query = num_query\n",
    "\n",
    "    def get_task(self):\n",
    "        indices = list(range(len(self.data)))\n",
    "        random.shuffle(indices)\n",
    "\n",
    "        support_indices = indices[:self.num_support]\n",
    "        query_indices = indices[self.num_support:self.num_support + self.num_query]\n",
    "\n",
    "        support_set = [(self.data[i]['text'], self.data[i]['label']) for i in support_indices]\n",
    "        query_set = [(self.data[i]['text'], self.data[i]['label']) for i in query_indices]\n",
    "\n",
    "        return support_set, query_set"
   ],
   "id": "859ce03cf1b6b634",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T20:52:09.905852Z",
     "start_time": "2025-01-30T20:52:09.418955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_path = \"NLP_VER1\"\n",
    "base_model = DistilBertForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ],
   "id": "7e5b949d8dd1d9b9",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T20:52:10.346711Z",
     "start_time": "2025-01-30T20:52:09.921569Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "base_model.to(device)\n",
    "\n",
    "def inner_loop(model, support_set, num_steps=1, lr=1e-5):\n",
    "    task_model = deepcopy(model).to(device)  # Move task-specific model to GPU\n",
    "    optimizer = torch.optim.Adam(task_model.parameters(), lr=lr)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for _ in range(num_steps):\n",
    "        for text, label in support_set:\n",
    "            inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "            labels = torch.tensor([label]).unsqueeze(0).to(device)  # Move labels to GPU\n",
    "\n",
    "            outputs = task_model(**inputs, labels=labels)\n",
    "            loss = outputs.loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    return task_model"
   ],
   "id": "4d465330344cc7e5",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T20:52:10.374937Z",
     "start_time": "2025-01-30T20:52:10.362853Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def outer_loop(meta_model, tasks, meta_optimizer, num_inner_steps=1):\n",
    "    meta_optimizer.zero_grad()\n",
    "    total_loss = 0\n",
    "\n",
    "    for support_set, query_set in tasks:\n",
    "        task_model = inner_loop(meta_model, support_set, num_steps=num_inner_steps)\n",
    "\n",
    "        for text, label in query_set:\n",
    "            inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "            labels = torch.tensor([label]).unsqueeze(0).to(device)\n",
    "\n",
    "            outputs = task_model(**inputs, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss\n",
    "\n",
    "    total_loss.backward()\n",
    "    meta_optimizer.step()\n",
    "\n",
    "    return total_loss.item()"
   ],
   "id": "e14ed62ddf11eb0d",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T20:52:10.435100Z",
     "start_time": "2025-01-30T20:52:10.420019Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def objective(trial):\n",
    "    meta_lr = trial.suggest_loguniform(\"meta_lr\", 1e-5, 1e-3)\n",
    "    inner_lr = trial.suggest_loguniform(\"inner_lr\", 1e-5, 1e-3)\n",
    "    num_support = trial.suggest_int(\"num_support\", 1, 10)\n",
    "    num_query = trial.suggest_int(\"num_query\", 1, 10)\n",
    "    inner_steps = trial.suggest_int(\"inner_steps\", 1, 5)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 2, 8)\n",
    "    meta_epochs = trial.suggest_int(\"meta_epochs\", 5, 10)\n",
    "\n",
    "    dataset_name = random.choice(dataset_names)\n",
    "    few_shot_dataset = FewShotDataset(train_data[dataset_name], num_support, num_query)\n",
    "\n",
    "    meta_optimizer = Adam(base_model.parameters(), lr=meta_lr)\n",
    "\n",
    "    for epoch in range(meta_epochs):\n",
    "        tasks = [few_shot_dataset.get_task() for _ in range(batch_size)]\n",
    "        loss = outer_loop(base_model, tasks, meta_optimizer, num_inner_steps=inner_steps)\n",
    "\n",
    "        wandb.log({\n",
    "            \"trial\": trial.number,\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"meta_loss\": loss,\n",
    "            \"meta_lr\": meta_lr,\n",
    "            \"inner_lr\": inner_lr,\n",
    "            \"num_support\": num_support,\n",
    "            \"num_query\": num_query,\n",
    "            \"inner_steps\": inner_steps,\n",
    "            \"batch_size\": batch_size,\n",
    "        })\n",
    "\n",
    "        print(f\"[Trial {trial.number}, Epoch {epoch + 1}] Loss: {loss:.4f}\")\n",
    "\n",
    "    return loss"
   ],
   "id": "4ddfd6735ed70a86",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T23:50:56.041989Z",
     "start_time": "2025-01-30T20:52:40.404051Z"
    }
   },
   "cell_type": "code",
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=34)\n",
    "\n",
    "best_trial = study.best_trial\n",
    "print(f\"Best Trial: {best_trial.number}, Loss: {best_trial.value}\")\n",
    "print(\"Best Hyperparameters:\", best_trial.params)"
   ],
   "id": "59c74ee74ee93580",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 21:52:40,410] A new study created in memory with name: no-name-25124f3e-a74c-4f17-82ff-59787b330d7e\n",
      "C:\\Users\\Korisnik\\AppData\\Local\\Temp\\ipykernel_16660\\974922913.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  meta_lr = trial.suggest_loguniform(\"meta_lr\", 1e-5, 1e-3)\n",
      "C:\\Users\\Korisnik\\AppData\\Local\\Temp\\ipykernel_16660\\974922913.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  inner_lr = trial.suggest_loguniform(\"inner_lr\", 1e-5, 1e-3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 0, Epoch 1] Loss: 23.6549\n",
      "[Trial 0, Epoch 2] Loss: 4.3525\n",
      "[Trial 0, Epoch 3] Loss: 15.8666\n",
      "[Trial 0, Epoch 4] Loss: 11.7129\n",
      "[Trial 0, Epoch 5] Loss: 6.9439\n",
      "[Trial 0, Epoch 6] Loss: 9.8187\n",
      "[Trial 0, Epoch 7] Loss: 5.4228\n",
      "[Trial 0, Epoch 8] Loss: 12.7705\n",
      "[Trial 0, Epoch 9] Loss: 4.7034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 22:00:25,321] Trial 0 finished with value: 4.703431606292725 and parameters: {'meta_lr': 0.00012765534849510702, 'inner_lr': 1.9468831996027415e-05, 'num_support': 9, 'num_query': 4, 'inner_steps': 5, 'batch_size': 6, 'meta_epochs': 9}. Best is trial 0 with value: 4.703431606292725.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 1, Epoch 1] Loss: 34.0209\n",
      "[Trial 1, Epoch 2] Loss: 13.9256\n",
      "[Trial 1, Epoch 3] Loss: 13.2510\n",
      "[Trial 1, Epoch 4] Loss: 8.4297\n",
      "[Trial 1, Epoch 5] Loss: 12.9661\n",
      "[Trial 1, Epoch 6] Loss: 18.4708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 22:02:28,265] Trial 1 finished with value: 18.4708251953125 and parameters: {'meta_lr': 1.9320689557340608e-05, 'inner_lr': 0.00019001272780410218, 'num_support': 6, 'num_query': 8, 'inner_steps': 4, 'batch_size': 5, 'meta_epochs': 6}. Best is trial 0 with value: 4.703431606292725.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 2, Epoch 1] Loss: 6.7252\n",
      "[Trial 2, Epoch 2] Loss: 2.0755\n",
      "[Trial 2, Epoch 3] Loss: 0.5456\n",
      "[Trial 2, Epoch 4] Loss: 3.7954\n",
      "[Trial 2, Epoch 5] Loss: 4.2484\n",
      "[Trial 2, Epoch 6] Loss: 4.1412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 22:03:15,191] Trial 2 finished with value: 4.1411824226379395 and parameters: {'meta_lr': 3.9060169472092286e-05, 'inner_lr': 3.182033474887267e-05, 'num_support': 6, 'num_query': 2, 'inner_steps': 2, 'batch_size': 2, 'meta_epochs': 6}. Best is trial 2 with value: 4.1411824226379395.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 3, Epoch 1] Loss: 5.6219\n",
      "[Trial 3, Epoch 2] Loss: 10.0801\n",
      "[Trial 3, Epoch 3] Loss: 10.7330\n",
      "[Trial 3, Epoch 4] Loss: 18.7148\n",
      "[Trial 3, Epoch 5] Loss: 11.6823\n",
      "[Trial 3, Epoch 6] Loss: 5.0801\n",
      "[Trial 3, Epoch 7] Loss: 4.5051\n",
      "[Trial 3, Epoch 8] Loss: 13.6569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 22:07:08,144] Trial 3 finished with value: 13.656900405883789 and parameters: {'meta_lr': 2.0907685277119343e-05, 'inner_lr': 1.7668644805978523e-05, 'num_support': 3, 'num_query': 8, 'inner_steps': 3, 'batch_size': 4, 'meta_epochs': 8}. Best is trial 2 with value: 4.1411824226379395.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 4, Epoch 1] Loss: 3.6463\n",
      "[Trial 4, Epoch 2] Loss: 6.3260\n",
      "[Trial 4, Epoch 3] Loss: 0.1661\n",
      "[Trial 4, Epoch 4] Loss: 4.9609\n",
      "[Trial 4, Epoch 5] Loss: 1.0969\n",
      "[Trial 4, Epoch 6] Loss: 0.5304\n",
      "[Trial 4, Epoch 7] Loss: 4.7963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 22:08:53,425] Trial 4 finished with value: 4.796279430389404 and parameters: {'meta_lr': 0.000915923776610583, 'inner_lr': 0.0002075165155870697, 'num_support': 5, 'num_query': 6, 'inner_steps': 1, 'batch_size': 2, 'meta_epochs': 7}. Best is trial 2 with value: 4.1411824226379395.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 5, Epoch 1] Loss: 5.1177\n",
      "[Trial 5, Epoch 2] Loss: 2.0561\n",
      "[Trial 5, Epoch 3] Loss: 0.2264\n",
      "[Trial 5, Epoch 4] Loss: 2.5274\n",
      "[Trial 5, Epoch 5] Loss: 12.1637\n",
      "[Trial 5, Epoch 6] Loss: 1.2927\n",
      "[Trial 5, Epoch 7] Loss: 6.7408\n",
      "[Trial 5, Epoch 8] Loss: 5.7796\n",
      "[Trial 5, Epoch 9] Loss: 1.4448\n",
      "[Trial 5, Epoch 10] Loss: 1.1115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 22:10:08,499] Trial 5 finished with value: 1.1114599704742432 and parameters: {'meta_lr': 0.00013603828869305698, 'inner_lr': 0.0003754408822980123, 'num_support': 5, 'num_query': 3, 'inner_steps': 2, 'batch_size': 4, 'meta_epochs': 10}. Best is trial 5 with value: 1.1114599704742432.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 6, Epoch 1] Loss: 7.6003\n",
      "[Trial 6, Epoch 2] Loss: 7.7233\n",
      "[Trial 6, Epoch 3] Loss: 16.8586\n",
      "[Trial 6, Epoch 4] Loss: 13.8449\n",
      "[Trial 6, Epoch 5] Loss: 7.7543\n",
      "[Trial 6, Epoch 6] Loss: 5.9565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 22:10:53,947] Trial 6 finished with value: 5.956506729125977 and parameters: {'meta_lr': 0.0007795386475656917, 'inner_lr': 0.000988254249791263, 'num_support': 4, 'num_query': 7, 'inner_steps': 2, 'batch_size': 2, 'meta_epochs': 6}. Best is trial 5 with value: 1.1114599704742432.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 7, Epoch 1] Loss: 4.5838\n",
      "[Trial 7, Epoch 2] Loss: 10.8669\n",
      "[Trial 7, Epoch 3] Loss: 2.4891\n",
      "[Trial 7, Epoch 4] Loss: 5.9419\n",
      "[Trial 7, Epoch 5] Loss: 7.5549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 22:11:55,904] Trial 7 finished with value: 7.554874897003174 and parameters: {'meta_lr': 0.00010657913547510096, 'inner_lr': 0.0005362744747230688, 'num_support': 5, 'num_query': 4, 'inner_steps': 5, 'batch_size': 4, 'meta_epochs': 5}. Best is trial 5 with value: 1.1114599704742432.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 8, Epoch 1] Loss: 20.3686\n",
      "[Trial 8, Epoch 2] Loss: 9.7355\n",
      "[Trial 8, Epoch 3] Loss: 10.6000\n",
      "[Trial 8, Epoch 4] Loss: 20.0862\n",
      "[Trial 8, Epoch 5] Loss: 8.9484\n",
      "[Trial 8, Epoch 6] Loss: 10.8548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 22:16:09,264] Trial 8 finished with value: 10.854832649230957 and parameters: {'meta_lr': 0.00013923684312892843, 'inner_lr': 0.0006217252382166167, 'num_support': 3, 'num_query': 9, 'inner_steps': 5, 'batch_size': 5, 'meta_epochs': 6}. Best is trial 5 with value: 1.1114599704742432.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 9, Epoch 1] Loss: 3.7133\n",
      "[Trial 9, Epoch 2] Loss: 4.7007\n",
      "[Trial 9, Epoch 3] Loss: 5.1362\n",
      "[Trial 9, Epoch 4] Loss: 9.0248\n",
      "[Trial 9, Epoch 5] Loss: 6.2047\n",
      "[Trial 9, Epoch 6] Loss: 13.5139\n",
      "[Trial 9, Epoch 7] Loss: 6.5189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 22:24:23,360] Trial 9 finished with value: 6.51888370513916 and parameters: {'meta_lr': 7.067011693902542e-05, 'inner_lr': 0.00011113736713401701, 'num_support': 5, 'num_query': 4, 'inner_steps': 5, 'batch_size': 7, 'meta_epochs': 7}. Best is trial 5 with value: 1.1114599704742432.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 10, Epoch 1] Loss: 3.3815\n",
      "[Trial 10, Epoch 2] Loss: 1.5572\n",
      "[Trial 10, Epoch 3] Loss: 0.6036\n",
      "[Trial 10, Epoch 4] Loss: 0.1500\n",
      "[Trial 10, Epoch 5] Loss: 5.2355\n",
      "[Trial 10, Epoch 6] Loss: 8.9201\n",
      "[Trial 10, Epoch 7] Loss: 0.0986\n",
      "[Trial 10, Epoch 8] Loss: 2.5974\n",
      "[Trial 10, Epoch 9] Loss: 4.5319\n",
      "[Trial 10, Epoch 10] Loss: 0.6450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 22:33:48,238] Trial 10 finished with value: 0.6449998021125793 and parameters: {'meta_lr': 0.00032927120859901817, 'inner_lr': 4.956300757463975e-05, 'num_support': 1, 'num_query': 1, 'inner_steps': 1, 'batch_size': 8, 'meta_epochs': 10}. Best is trial 10 with value: 0.6449998021125793.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 11, Epoch 1] Loss: 5.5753\n",
      "[Trial 11, Epoch 2] Loss: 0.2168\n",
      "[Trial 11, Epoch 3] Loss: 0.0567\n",
      "[Trial 11, Epoch 4] Loss: 3.0650\n",
      "[Trial 11, Epoch 5] Loss: 0.0781\n",
      "[Trial 11, Epoch 6] Loss: 0.6767\n",
      "[Trial 11, Epoch 7] Loss: 0.0468\n",
      "[Trial 11, Epoch 8] Loss: 4.5873\n",
      "[Trial 11, Epoch 9] Loss: 1.0222\n",
      "[Trial 11, Epoch 10] Loss: 4.2074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 22:41:44,212] Trial 11 finished with value: 4.207398891448975 and parameters: {'meta_lr': 0.00034125878374823796, 'inner_lr': 4.745993889530881e-05, 'num_support': 1, 'num_query': 1, 'inner_steps': 1, 'batch_size': 8, 'meta_epochs': 10}. Best is trial 10 with value: 0.6449998021125793.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 12, Epoch 1] Loss: 9.3527\n",
      "[Trial 12, Epoch 2] Loss: 9.0494\n",
      "[Trial 12, Epoch 3] Loss: 0.2407\n",
      "[Trial 12, Epoch 4] Loss: 11.6954\n",
      "[Trial 12, Epoch 5] Loss: 4.4752\n",
      "[Trial 12, Epoch 6] Loss: 5.2841\n",
      "[Trial 12, Epoch 7] Loss: 0.8155\n",
      "[Trial 12, Epoch 8] Loss: 1.1046\n",
      "[Trial 12, Epoch 9] Loss: 12.2626\n",
      "[Trial 12, Epoch 10] Loss: 0.2172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 22:43:58,821] Trial 12 finished with value: 0.217221200466156 and parameters: {'meta_lr': 0.00033269093101486407, 'inner_lr': 6.15019569557295e-05, 'num_support': 1, 'num_query': 2, 'inner_steps': 2, 'batch_size': 8, 'meta_epochs': 10}. Best is trial 12 with value: 0.217221200466156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 13, Epoch 1] Loss: 0.4027\n",
      "[Trial 13, Epoch 2] Loss: 0.2820\n",
      "[Trial 13, Epoch 3] Loss: 2.9965\n",
      "[Trial 13, Epoch 4] Loss: 1.2060\n",
      "[Trial 13, Epoch 5] Loss: 0.0770\n",
      "[Trial 13, Epoch 6] Loss: 2.4142\n",
      "[Trial 13, Epoch 7] Loss: 5.5846\n",
      "[Trial 13, Epoch 8] Loss: 0.7309\n",
      "[Trial 13, Epoch 9] Loss: 0.1633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 22:50:49,011] Trial 13 finished with value: 0.16325432062149048 and parameters: {'meta_lr': 0.0003238870723018769, 'inner_lr': 5.3011413355797864e-05, 'num_support': 1, 'num_query': 1, 'inner_steps': 1, 'batch_size': 8, 'meta_epochs': 9}. Best is trial 13 with value: 0.16325432062149048.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 14, Epoch 1] Loss: 9.7654\n",
      "[Trial 14, Epoch 2] Loss: 5.6957\n",
      "[Trial 14, Epoch 3] Loss: 16.7275\n",
      "[Trial 14, Epoch 4] Loss: 4.7089\n",
      "[Trial 14, Epoch 5] Loss: 7.8915\n",
      "[Trial 14, Epoch 6] Loss: 11.6817\n",
      "[Trial 14, Epoch 7] Loss: 11.3146\n",
      "[Trial 14, Epoch 8] Loss: 10.9585\n",
      "[Trial 14, Epoch 9] Loss: 15.3361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 22:54:01,714] Trial 14 finished with value: 15.3361234664917 and parameters: {'meta_lr': 0.00033794521816553905, 'inner_lr': 8.021191636520669e-05, 'num_support': 2, 'num_query': 2, 'inner_steps': 3, 'batch_size': 7, 'meta_epochs': 9}. Best is trial 13 with value: 0.16325432062149048.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 15, Epoch 1] Loss: 3.0469\n",
      "[Trial 15, Epoch 2] Loss: 3.2333\n",
      "[Trial 15, Epoch 3] Loss: 5.2038\n",
      "[Trial 15, Epoch 4] Loss: 0.0931\n",
      "[Trial 15, Epoch 5] Loss: 6.0406\n",
      "[Trial 15, Epoch 6] Loss: 0.2199\n",
      "[Trial 15, Epoch 7] Loss: 0.4189\n",
      "[Trial 15, Epoch 8] Loss: 3.0387\n",
      "[Trial 15, Epoch 9] Loss: 4.4924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 22:56:58,193] Trial 15 finished with value: 4.492351055145264 and parameters: {'meta_lr': 0.0005426389346370192, 'inner_lr': 9.844128211442174e-05, 'num_support': 8, 'num_query': 1, 'inner_steps': 2, 'batch_size': 7, 'meta_epochs': 9}. Best is trial 13 with value: 0.16325432062149048.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 16, Epoch 1] Loss: 8.2102\n",
      "[Trial 16, Epoch 2] Loss: 10.4556\n",
      "[Trial 16, Epoch 3] Loss: 9.3189\n",
      "[Trial 16, Epoch 4] Loss: 9.5959\n",
      "[Trial 16, Epoch 5] Loss: 5.8101\n",
      "[Trial 16, Epoch 6] Loss: 0.6800\n",
      "[Trial 16, Epoch 7] Loss: 6.8624\n",
      "[Trial 16, Epoch 8] Loss: 7.1749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 23:05:00,203] Trial 16 finished with value: 7.174880027770996 and parameters: {'meta_lr': 0.000226673085895108, 'inner_lr': 1.1154669024398464e-05, 'num_support': 2, 'num_query': 3, 'inner_steps': 3, 'batch_size': 8, 'meta_epochs': 8}. Best is trial 13 with value: 0.16325432062149048.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 17, Epoch 1] Loss: 26.6707\n",
      "[Trial 17, Epoch 2] Loss: 42.1638\n",
      "[Trial 17, Epoch 3] Loss: 34.8392\n",
      "[Trial 17, Epoch 4] Loss: 24.0678\n",
      "[Trial 17, Epoch 5] Loss: 31.1372\n",
      "[Trial 17, Epoch 6] Loss: 14.0724\n",
      "[Trial 17, Epoch 7] Loss: 29.0780\n",
      "[Trial 17, Epoch 8] Loss: 21.6773\n",
      "[Trial 17, Epoch 9] Loss: 31.6127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 23:07:43,236] Trial 17 finished with value: 31.612667083740234 and parameters: {'meta_lr': 0.0005118623898126613, 'inner_lr': 5.440703132223809e-05, 'num_support': 1, 'num_query': 5, 'inner_steps': 1, 'batch_size': 6, 'meta_epochs': 9}. Best is trial 13 with value: 0.16325432062149048.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 18, Epoch 1] Loss: 3.4544\n",
      "[Trial 18, Epoch 2] Loss: 5.9648\n",
      "[Trial 18, Epoch 3] Loss: 1.9321\n",
      "[Trial 18, Epoch 4] Loss: 0.2536\n",
      "[Trial 18, Epoch 5] Loss: 0.2053\n",
      "[Trial 18, Epoch 6] Loss: 2.1856\n",
      "[Trial 18, Epoch 7] Loss: 0.2282\n",
      "[Trial 18, Epoch 8] Loss: 0.1818\n",
      "[Trial 18, Epoch 9] Loss: 5.4852\n",
      "[Trial 18, Epoch 10] Loss: 5.5686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 23:09:23,914] Trial 18 finished with value: 5.5686163902282715 and parameters: {'meta_lr': 1.0427803471929359e-05, 'inner_lr': 0.00016442350367569273, 'num_support': 3, 'num_query': 2, 'inner_steps': 2, 'batch_size': 6, 'meta_epochs': 10}. Best is trial 13 with value: 0.16325432062149048.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 19, Epoch 1] Loss: 72.1607\n",
      "[Trial 19, Epoch 2] Loss: 72.0202\n",
      "[Trial 19, Epoch 3] Loss: 70.6245\n",
      "[Trial 19, Epoch 4] Loss: 67.9339\n",
      "[Trial 19, Epoch 5] Loss: 49.7945\n",
      "[Trial 19, Epoch 6] Loss: 89.9792\n",
      "[Trial 19, Epoch 7] Loss: 82.3509\n",
      "[Trial 19, Epoch 8] Loss: 49.3305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 23:21:26,933] Trial 19 finished with value: 49.33052444458008 and parameters: {'meta_lr': 0.00022669005627067745, 'inner_lr': 2.864398423566454e-05, 'num_support': 7, 'num_query': 10, 'inner_steps': 4, 'batch_size': 8, 'meta_epochs': 8}. Best is trial 13 with value: 0.16325432062149048.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 20, Epoch 1] Loss: 8.7488\n",
      "[Trial 20, Epoch 2] Loss: 11.9792\n",
      "[Trial 20, Epoch 3] Loss: 10.2376\n",
      "[Trial 20, Epoch 4] Loss: 2.8145\n",
      "[Trial 20, Epoch 5] Loss: 5.2915\n",
      "[Trial 20, Epoch 6] Loss: 9.4012\n",
      "[Trial 20, Epoch 7] Loss: 2.1092\n",
      "[Trial 20, Epoch 8] Loss: 8.3260\n",
      "[Trial 20, Epoch 9] Loss: 10.5357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 23:23:36,494] Trial 20 finished with value: 10.535721778869629 and parameters: {'meta_lr': 0.00021916980239517213, 'inner_lr': 7.734374914693465e-05, 'num_support': 2, 'num_query': 3, 'inner_steps': 1, 'batch_size': 7, 'meta_epochs': 9}. Best is trial 13 with value: 0.16325432062149048.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 21, Epoch 1] Loss: 0.6227\n",
      "[Trial 21, Epoch 2] Loss: 0.1416\n",
      "[Trial 21, Epoch 3] Loss: 3.5031\n",
      "[Trial 21, Epoch 4] Loss: 4.7330\n",
      "[Trial 21, Epoch 5] Loss: 0.0866\n",
      "[Trial 21, Epoch 6] Loss: 4.6211\n",
      "[Trial 21, Epoch 7] Loss: 8.2899\n",
      "[Trial 21, Epoch 8] Loss: 5.0394\n",
      "[Trial 21, Epoch 9] Loss: 0.7418\n",
      "[Trial 21, Epoch 10] Loss: 0.0828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 23:26:40,288] Trial 21 finished with value: 0.0828155130147934 and parameters: {'meta_lr': 0.0004379174327349713, 'inner_lr': 4.4169684443381925e-05, 'num_support': 1, 'num_query': 1, 'inner_steps': 1, 'batch_size': 8, 'meta_epochs': 10}. Best is trial 21 with value: 0.0828155130147934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 22, Epoch 1] Loss: 0.3718\n",
      "[Trial 22, Epoch 2] Loss: 2.7505\n",
      "[Trial 22, Epoch 3] Loss: 0.2723\n",
      "[Trial 22, Epoch 4] Loss: 0.1587\n",
      "[Trial 22, Epoch 5] Loss: 3.5955\n",
      "[Trial 22, Epoch 6] Loss: 0.2516\n",
      "[Trial 22, Epoch 7] Loss: 0.2252\n",
      "[Trial 22, Epoch 8] Loss: 0.2736\n",
      "[Trial 22, Epoch 9] Loss: 0.1225\n",
      "[Trial 22, Epoch 10] Loss: 0.4475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 23:30:38,112] Trial 22 finished with value: 0.44751641154289246 and parameters: {'meta_lr': 0.0005244498440478509, 'inner_lr': 3.280215359934574e-05, 'num_support': 1, 'num_query': 1, 'inner_steps': 1, 'batch_size': 8, 'meta_epochs': 10}. Best is trial 21 with value: 0.0828155130147934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 23, Epoch 1] Loss: 6.9694\n",
      "[Trial 23, Epoch 2] Loss: 6.4900\n",
      "[Trial 23, Epoch 3] Loss: 8.8578\n",
      "[Trial 23, Epoch 4] Loss: 9.2669\n",
      "[Trial 23, Epoch 5] Loss: 0.6901\n",
      "[Trial 23, Epoch 6] Loss: 1.0208\n",
      "[Trial 23, Epoch 7] Loss: 4.2944\n",
      "[Trial 23, Epoch 8] Loss: 0.5860\n",
      "[Trial 23, Epoch 9] Loss: 2.2045\n",
      "[Trial 23, Epoch 10] Loss: 3.4968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 23:36:45,177] Trial 23 finished with value: 3.496807813644409 and parameters: {'meta_lr': 6.882335057400459e-05, 'inner_lr': 5.418672312165638e-05, 'num_support': 2, 'num_query': 2, 'inner_steps': 2, 'batch_size': 7, 'meta_epochs': 10}. Best is trial 21 with value: 0.0828155130147934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 24, Epoch 1] Loss: 0.0572\n",
      "[Trial 24, Epoch 2] Loss: 0.6370\n",
      "[Trial 24, Epoch 3] Loss: 9.6591\n",
      "[Trial 24, Epoch 4] Loss: 4.6616\n",
      "[Trial 24, Epoch 5] Loss: 9.5747\n",
      "[Trial 24, Epoch 6] Loss: 4.7506\n",
      "[Trial 24, Epoch 7] Loss: 5.1325\n",
      "[Trial 24, Epoch 8] Loss: 0.0946\n",
      "[Trial 24, Epoch 9] Loss: 2.7783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 23:49:36,657] Trial 24 finished with value: 2.7782809734344482 and parameters: {'meta_lr': 0.0006880609098856353, 'inner_lr': 2.4567011872998434e-05, 'num_support': 3, 'num_query': 1, 'inner_steps': 1, 'batch_size': 8, 'meta_epochs': 9}. Best is trial 21 with value: 0.0828155130147934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 25, Epoch 1] Loss: 21.5747\n",
      "[Trial 25, Epoch 2] Loss: 11.5926\n",
      "[Trial 25, Epoch 3] Loss: 14.5048\n",
      "[Trial 25, Epoch 4] Loss: 26.3094\n",
      "[Trial 25, Epoch 5] Loss: 8.8375\n",
      "[Trial 25, Epoch 6] Loss: 14.2636\n",
      "[Trial 25, Epoch 7] Loss: 17.9615\n",
      "[Trial 25, Epoch 8] Loss: 17.6540\n",
      "[Trial 25, Epoch 9] Loss: 22.3820\n",
      "[Trial 25, Epoch 10] Loss: 14.9552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-30 23:57:08,637] Trial 25 finished with value: 14.955235481262207 and parameters: {'meta_lr': 0.00040357533758133993, 'inner_lr': 0.00013608277326632252, 'num_support': 10, 'num_query': 3, 'inner_steps': 2, 'batch_size': 6, 'meta_epochs': 10}. Best is trial 21 with value: 0.0828155130147934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 26, Epoch 1] Loss: 12.8727\n",
      "[Trial 26, Epoch 2] Loss: 11.7881\n",
      "[Trial 26, Epoch 3] Loss: 7.7704\n",
      "[Trial 26, Epoch 4] Loss: 7.2614\n",
      "[Trial 26, Epoch 5] Loss: 11.3088\n",
      "[Trial 26, Epoch 6] Loss: 14.0818\n",
      "[Trial 26, Epoch 7] Loss: 13.3330\n",
      "[Trial 26, Epoch 8] Loss: 11.9786\n",
      "[Trial 26, Epoch 9] Loss: 9.2271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-31 00:08:42,688] Trial 26 finished with value: 9.227128982543945 and parameters: {'meta_lr': 0.00019132031555773533, 'inner_lr': 7.057665012524313e-05, 'num_support': 4, 'num_query': 5, 'inner_steps': 1, 'batch_size': 7, 'meta_epochs': 9}. Best is trial 21 with value: 0.0828155130147934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 27, Epoch 1] Loss: 7.0552\n",
      "[Trial 27, Epoch 2] Loss: 1.7751\n",
      "[Trial 27, Epoch 3] Loss: 6.5154\n",
      "[Trial 27, Epoch 4] Loss: 2.6272\n",
      "[Trial 27, Epoch 5] Loss: 9.3366\n",
      "[Trial 27, Epoch 6] Loss: 0.3050\n",
      "[Trial 27, Epoch 7] Loss: 9.8438\n",
      "[Trial 27, Epoch 8] Loss: 5.0220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-31 00:14:13,994] Trial 27 finished with value: 5.0219926834106445 and parameters: {'meta_lr': 0.00028526053252671583, 'inner_lr': 3.779658024658e-05, 'num_support': 1, 'num_query': 2, 'inner_steps': 2, 'batch_size': 8, 'meta_epochs': 8}. Best is trial 21 with value: 0.0828155130147934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 28, Epoch 1] Loss: 0.0268\n",
      "[Trial 28, Epoch 2] Loss: 0.0634\n",
      "[Trial 28, Epoch 3] Loss: 0.8177\n",
      "[Trial 28, Epoch 4] Loss: 0.0292\n",
      "[Trial 28, Epoch 5] Loss: 0.0214\n",
      "[Trial 28, Epoch 6] Loss: 3.3039\n",
      "[Trial 28, Epoch 7] Loss: 0.0155\n",
      "[Trial 28, Epoch 8] Loss: 0.0286\n",
      "[Trial 28, Epoch 9] Loss: 0.0179\n",
      "[Trial 28, Epoch 10] Loss: 0.9515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-31 00:15:10,906] Trial 28 finished with value: 0.9514747262001038 and parameters: {'meta_lr': 0.0009507391356933477, 'inner_lr': 1.0484071063564204e-05, 'num_support': 2, 'num_query': 1, 'inner_steps': 1, 'batch_size': 3, 'meta_epochs': 10}. Best is trial 21 with value: 0.0828155130147934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 29, Epoch 1] Loss: 10.6670\n",
      "[Trial 29, Epoch 2] Loss: 14.9919\n",
      "[Trial 29, Epoch 3] Loss: 4.1333\n",
      "[Trial 29, Epoch 4] Loss: 5.8490\n",
      "[Trial 29, Epoch 5] Loss: 12.1909\n",
      "[Trial 29, Epoch 6] Loss: 8.3282\n",
      "[Trial 29, Epoch 7] Loss: 13.5090\n",
      "[Trial 29, Epoch 8] Loss: 12.4762\n",
      "[Trial 29, Epoch 9] Loss: 15.5459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-31 00:25:32,070] Trial 29 finished with value: 15.54587459564209 and parameters: {'meta_lr': 0.00017839248714827044, 'inner_lr': 1.6116423869207887e-05, 'num_support': 4, 'num_query': 4, 'inner_steps': 2, 'batch_size': 7, 'meta_epochs': 9}. Best is trial 21 with value: 0.0828155130147934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 30, Epoch 1] Loss: 2.8531\n",
      "[Trial 30, Epoch 2] Loss: 3.0713\n",
      "[Trial 30, Epoch 3] Loss: 0.1044\n",
      "[Trial 30, Epoch 4] Loss: 2.8426\n",
      "[Trial 30, Epoch 5] Loss: 1.4634\n",
      "[Trial 30, Epoch 6] Loss: 0.1281\n",
      "[Trial 30, Epoch 7] Loss: 14.8360\n",
      "[Trial 30, Epoch 8] Loss: 1.8040\n",
      "[Trial 30, Epoch 9] Loss: 3.8561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-31 00:26:33,813] Trial 30 finished with value: 3.8561410903930664 and parameters: {'meta_lr': 0.0004846190927487317, 'inner_lr': 0.0002630738800558842, 'num_support': 1, 'num_query': 2, 'inner_steps': 3, 'batch_size': 5, 'meta_epochs': 9}. Best is trial 21 with value: 0.0828155130147934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 31, Epoch 1] Loss: 0.1481\n",
      "[Trial 31, Epoch 2] Loss: 3.7985\n",
      "[Trial 31, Epoch 3] Loss: 0.1614\n",
      "[Trial 31, Epoch 4] Loss: 0.4472\n",
      "[Trial 31, Epoch 5] Loss: 2.1438\n",
      "[Trial 31, Epoch 6] Loss: 4.3411\n",
      "[Trial 31, Epoch 7] Loss: 0.0665\n",
      "[Trial 31, Epoch 8] Loss: 2.3211\n",
      "[Trial 31, Epoch 9] Loss: 2.7652\n",
      "[Trial 31, Epoch 10] Loss: 0.1597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-31 00:36:44,657] Trial 31 finished with value: 0.15974721312522888 and parameters: {'meta_lr': 0.0006764764640143719, 'inner_lr': 3.7697683888844164e-05, 'num_support': 1, 'num_query': 1, 'inner_steps': 1, 'batch_size': 8, 'meta_epochs': 10}. Best is trial 21 with value: 0.0828155130147934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 32, Epoch 1] Loss: 1.1204\n",
      "[Trial 32, Epoch 2] Loss: 0.9243\n",
      "[Trial 32, Epoch 3] Loss: 8.6580\n",
      "[Trial 32, Epoch 4] Loss: 5.2228\n",
      "[Trial 32, Epoch 5] Loss: 2.1078\n",
      "[Trial 32, Epoch 6] Loss: 8.3319\n",
      "[Trial 32, Epoch 7] Loss: 6.8379\n",
      "[Trial 32, Epoch 8] Loss: 5.0200\n",
      "[Trial 32, Epoch 9] Loss: 6.1424\n",
      "[Trial 32, Epoch 10] Loss: 6.6841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-31 00:43:40,338] Trial 32 finished with value: 6.684129238128662 and parameters: {'meta_lr': 0.0006922877388649675, 'inner_lr': 4.230670857459767e-05, 'num_support': 2, 'num_query': 1, 'inner_steps': 1, 'batch_size': 8, 'meta_epochs': 10}. Best is trial 21 with value: 0.0828155130147934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trial 33, Epoch 1] Loss: 15.6074\n",
      "[Trial 33, Epoch 2] Loss: 21.4301\n",
      "[Trial 33, Epoch 3] Loss: 12.6821\n",
      "[Trial 33, Epoch 4] Loss: 15.6322\n",
      "[Trial 33, Epoch 5] Loss: 6.1121\n",
      "[Trial 33, Epoch 6] Loss: 13.2195\n",
      "[Trial 33, Epoch 7] Loss: 15.3118\n",
      "[Trial 33, Epoch 8] Loss: 13.5080\n",
      "[Trial 33, Epoch 9] Loss: 7.3450\n",
      "[Trial 33, Epoch 10] Loss: 17.0412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-31 00:50:56,025] Trial 33 finished with value: 17.041229248046875 and parameters: {'meta_lr': 0.0004067884856220484, 'inner_lr': 2.4374013218275132e-05, 'num_support': 1, 'num_query': 2, 'inner_steps': 1, 'batch_size': 8, 'meta_epochs': 10}. Best is trial 21 with value: 0.0828155130147934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Trial: 21, Loss: 0.0828155130147934\n",
      "Best Hyperparameters: {'meta_lr': 0.0004379174327349713, 'inner_lr': 4.4169684443381925e-05, 'num_support': 1, 'num_query': 1, 'inner_steps': 1, 'batch_size': 8, 'meta_epochs': 10}\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T00:14:20.274860Z",
     "start_time": "2025-01-31T00:10:20.451868Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Meta Loss: 4.1011\n",
      "Epoch 2, Meta Loss: 3.2963\n",
      "Epoch 3, Meta Loss: 4.5106\n",
      "Epoch 4, Meta Loss: 3.4007\n",
      "Epoch 5, Meta Loss: 7.4569\n",
      "Epoch 6, Meta Loss: 9.8577\n",
      "Epoch 7, Meta Loss: 5.2001\n",
      "Epoch 8, Meta Loss: 11.9975\n",
      "Epoch 9, Meta Loss: 10.9002\n",
      "Epoch 10, Meta Loss: 6.7005\n"
     ]
    }
   ],
   "execution_count": 12,
   "source": [
    "best_params = best_trial.params\n",
    "dataset_name = random.choice(dataset_names)\n",
    "few_shot_dataset = FewShotDataset(train_data[dataset_name], best_params[\"num_support\"], best_params[\"num_query\"])\n",
    "meta_optimizer = Adam(base_model.parameters(), lr=best_params[\"meta_lr\"])\n",
    "\n",
    "for epoch in range(best_params[\"meta_epochs\"]):\n",
    "    tasks = [few_shot_dataset.get_task() for _ in range(best_params[\"batch_size\"])]\n",
    "    loss = outer_loop(base_model, tasks, meta_optimizer, num_inner_steps=best_params[\"inner_steps\"])\n",
    "    wandb.log({\"epoch\": epoch + 1, \"meta_loss\": loss})\n",
    "    print(f\"Epoch {epoch + 1}, Meta Loss: {loss:.4f}\")"
   ],
   "id": "e277fa3ae2b32175"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T00:14:21.402368Z",
     "start_time": "2025-01-31T00:14:20.458243Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Task (amazon_polarity) Evaluation Loss: 0.0311\n"
     ]
    }
   ],
   "execution_count": 13,
   "source": [
    "new_dataset_name = random.choice(dataset_names)\n",
    "new_task_data = FewShotDataset(test_data[new_dataset_name], best_params[\"num_support\"], best_params[\"num_query\"])\n",
    "new_support_set, new_query_set = new_task_data.get_task()\n",
    "\n",
    "adapted_model = inner_loop(base_model, new_support_set, num_steps=best_params[\"inner_steps\"])\n",
    "adapted_model = adapted_model.to(device)\n",
    "total_loss = 0\n",
    "\n",
    "for text, label in new_query_set:\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "    labels = torch.tensor([label]).unsqueeze(0).to(device)\n",
    "\n",
    "\n",
    "    outputs = adapted_model(**inputs, labels=labels)\n",
    "    loss = outputs.loss\n",
    "    total_loss += loss\n",
    "\n",
    "wandb.log({\"new_task_loss\": total_loss.item()})\n",
    "print(f\"New Task ({new_dataset_name}) Evaluation Loss: {total_loss.item():.4f}\")"
   ],
   "id": "b9dfb3f184b3bbe2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#This code works but it takes hours to complete because of milions of instances\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "def evaluate_model_on_all_datasets(model, test_data):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for dataset_name in [\"sentiment140\", \"amazon_polarity\", \"yelp_polarity\"]:\n",
    "        encodings = tokenizer(test_data[dataset_name][\"text\"], padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "\n",
    "        test_dataset = torch.utils.data.TensorDataset(encodings.input_ids, encodings.attention_mask, torch.tensor(test_data[dataset_name][\"label\"]))\n",
    "        test_loader = DataLoader(test_dataset, batch_size=16)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                input_ids, attention_mask, labels = batch\n",
    "                input_ids = input_ids.to(model.device)\n",
    "                attention_mask = attention_mask.to(model.device)\n",
    "                labels = labels.to(model.device)\n",
    "\n",
    "                outputs = model(input_ids, attention_mask=attention_mask)\n",
    "                logits = outputs.logits\n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "        wandb.log({f\"{dataset_name}_accuracy\": accuracy})\n",
    "\n",
    "        print(f\"Evaluation on {dataset_name}: Accuracy = {accuracy:.4f}\")\n",
    "        print(f\"Classification Report for {dataset_name}:\")\n",
    "        print(classification_report(all_labels, all_preds))\n",
    "\n",
    "evaluate_model_on_all_datasets(adapted_model, test_data)"
   ],
   "id": "be3c305be80eb6e5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T09:22:43.847357Z",
     "start_time": "2025-01-31T09:22:42.303090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# 20 unseen sentences for testing\n",
    "test_sentences = [\n",
    "    \"The customer service was beyond my expectations!\",\n",
    "    \"I waited an hour for my order, and it was still wrong.\",\n",
    "    \"This new phone update is a complete disaster.\",\n",
    "    \"I'm absolutely thrilled with my new laptop!\",\n",
    "    \"The food was bland and overpriced, not coming back.\",\n",
    "    \"Best vacation spot ever, can't wait to return!\",\n",
    "    \"The product broke after just two uses, very disappointed.\",\n",
    "    \"Excellent book, well-written and engaging.\",\n",
    "    \"Movie was predictable and boring, nothing special.\",\n",
    "    \"Customer support was extremely helpful and quick to respond.\",\n",
    "    \"I regret purchasing this item, waste of money.\",\n",
    "    \"One of the best restaurants in town, highly recommended!\",\n",
    "    \"The new policy changes are frustrating and unnecessary.\",\n",
    "    \"I love how comfortable and stylish these shoes are!\",\n",
    "    \"The concert was an unforgettable experience.\",\n",
    "    \"The software crashes frequently, making it unusable.\",\n",
    "    \"Brilliant storytelling, kept me hooked from start to finish.\",\n",
    "    \"Shipping took forever, and the package arrived damaged.\",\n",
    "    \"Great workout program, helped me get in shape quickly.\",\n",
    "    \"The app's interface is confusing and hard to navigate.\"\n",
    "]\n",
    "\n",
    "inputs = tokenizer(test_sentences, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = adapted_model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=1)\n",
    "\n",
    "if isinstance(predictions, torch.Tensor):\n",
    "    predictions = predictions.cpu().numpy()\n",
    "predictions = predictions.tolist()\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "probs = F.softmax(logits, dim=1).cpu().numpy()\n",
    "for i, (sentence, prob) in enumerate(zip(test_sentences, probs)):\n",
    "    print(f\"{i+1}. {sentence}\\n   ➝ Positive: {prob[1]:.2f}, Negative: {prob[0]:.2f}\\n\")\n"
   ],
   "id": "3e13de2e09aab63e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. The customer service was beyond my expectations!\n",
      "   ➝ Positive: 0.92, Negative: 0.08\n",
      "\n",
      "2. I waited an hour for my order, and it was still wrong.\n",
      "   ➝ Positive: 0.01, Negative: 0.99\n",
      "\n",
      "3. This new phone update is a complete disaster.\n",
      "   ➝ Positive: 0.00, Negative: 1.00\n",
      "\n",
      "4. I'm absolutely thrilled with my new laptop!\n",
      "   ➝ Positive: 0.98, Negative: 0.02\n",
      "\n",
      "5. The food was bland and overpriced, not coming back.\n",
      "   ➝ Positive: 0.00, Negative: 1.00\n",
      "\n",
      "6. Best vacation spot ever, can't wait to return!\n",
      "   ➝ Positive: 0.99, Negative: 0.01\n",
      "\n",
      "7. The product broke after just two uses, very disappointed.\n",
      "   ➝ Positive: 0.00, Negative: 1.00\n",
      "\n",
      "8. Excellent book, well-written and engaging.\n",
      "   ➝ Positive: 1.00, Negative: 0.00\n",
      "\n",
      "9. Movie was predictable and boring, nothing special.\n",
      "   ➝ Positive: 0.00, Negative: 1.00\n",
      "\n",
      "10. Customer support was extremely helpful and quick to respond.\n",
      "   ➝ Positive: 0.98, Negative: 0.02\n",
      "\n",
      "11. I regret purchasing this item, waste of money.\n",
      "   ➝ Positive: 0.00, Negative: 1.00\n",
      "\n",
      "12. One of the best restaurants in town, highly recommended!\n",
      "   ➝ Positive: 1.00, Negative: 0.00\n",
      "\n",
      "13. The new policy changes are frustrating and unnecessary.\n",
      "   ➝ Positive: 0.00, Negative: 1.00\n",
      "\n",
      "14. I love how comfortable and stylish these shoes are!\n",
      "   ➝ Positive: 0.99, Negative: 0.01\n",
      "\n",
      "15. The concert was an unforgettable experience.\n",
      "   ➝ Positive: 0.98, Negative: 0.02\n",
      "\n",
      "16. The software crashes frequently, making it unusable.\n",
      "   ➝ Positive: 0.01, Negative: 0.99\n",
      "\n",
      "17. Brilliant storytelling, kept me hooked from start to finish.\n",
      "   ➝ Positive: 1.00, Negative: 0.00\n",
      "\n",
      "18. Shipping took forever, and the package arrived damaged.\n",
      "   ➝ Positive: 0.11, Negative: 0.89\n",
      "\n",
      "19. Great workout program, helped me get in shape quickly.\n",
      "   ➝ Positive: 0.99, Negative: 0.01\n",
      "\n",
      "20. The app's interface is confusing and hard to navigate.\n",
      "   ➝ Positive: 0.05, Negative: 0.95\n",
      "\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T08:47:01.875783Z",
     "start_time": "2025-01-31T08:46:59.038206Z"
    }
   },
   "cell_type": "code",
   "source": "wandb.finish()",
   "id": "149ebd6ce2ebbc0a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_size</td><td>▆▅▁▃▁▃▁▅▇██████▇▇▇▆▆▇▇▇████▇██▆▇██▂█████</td></tr><tr><td>epoch</td><td>▃▃▃▁▃▄▄▃▃▁▁▂▄▇▅▃▄▁▆▂▂▃▄▅▃▇█▁▃▇▄▄▂▁▂▄▁█▁▇</td></tr><tr><td>inner_lr</td><td>▁▂▂▁▂▄█▅▅▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▂▂▂▁▁▁▁▃▁▁▁▁▁▁▁</td></tr><tr><td>inner_steps</td><td>█▆▁▁▁▃██▁▁▃▁▁▁▃▁▃▃▆▁▁▁▁▁▃▁▁▃▃▃▅▅▅▅▁▁▁▁▁▁</td></tr><tr><td>meta_loss</td><td>▂▂▁▂▂▁▁▂▂▁▁▁▁▁▂▁▁▁▁▁▁▁▇▆█▁▂▂▁▂▂▁▂▁▁▁▂▂▁▁</td></tr><tr><td>meta_lr</td><td>▂▂▁▂▂▂▂▂▂▂▃▃▃▃▃▅▃▃▁▁▃▃▄▄▄▅▆▄▄▂███▂▅▅▅▆▆▄</td></tr><tr><td>new_task_loss</td><td>▁</td></tr><tr><td>num_query</td><td>▃▃▆▂▂▆▅▅▆▆▇▇▁▂▂▁▃▃▄▄▂█▃▁▁▂▂▁▁▁▄▄▂▃▃▂▁▁▂▂</td></tr><tr><td>num_support</td><td>█▅▅▃▅▅▄▅▅▃▁▁▁▁▁▂▂▇▂▂▂▁▃▂▂▁▂▂▂▂▃▄▁▁▁▄▁▁▂▁</td></tr><tr><td>sentiment140_accuracy</td><td>▁</td></tr><tr><td>trial</td><td>▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_size</td><td>8</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>inner_lr</td><td>2e-05</td></tr><tr><td>inner_steps</td><td>1</td></tr><tr><td>meta_loss</td><td>6.70054</td></tr><tr><td>meta_lr</td><td>0.00041</td></tr><tr><td>new_task_loss</td><td>0.03112</td></tr><tr><td>num_query</td><td>2</td></tr><tr><td>num_support</td><td>1</td></tr><tr><td>sentiment140_accuracy</td><td>0.76707</td></tr><tr><td>trial</td><td>33</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">maml-multiset-optuna</strong> at: <a href='https://wandb.ai/kostic-stojan23-university-of-belgrade/few-shot-multiset/runs/576zl4im' target=\"_blank\">https://wandb.ai/kostic-stojan23-university-of-belgrade/few-shot-multiset/runs/576zl4im</a><br> View project at: <a href='https://wandb.ai/kostic-stojan23-university-of-belgrade/few-shot-multiset' target=\"_blank\">https://wandb.ai/kostic-stojan23-university-of-belgrade/few-shot-multiset</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250130_215147-576zl4im\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
